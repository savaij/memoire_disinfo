\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Distribution of Facebook engagements for articles from true and fake news sources.\relax }}{15}{figure.caption.13}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Distribution of the sources in the dataset, colored by label\relax }}{16}{figure.caption.14}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces The distribution of user profile creation dates on PolitiFact and GossipCop splits of the dataset\relax }}{20}{figure.caption.19}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {PolitiFact dataset}}}{20}{figure.caption.19}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {GossipCop dataset}}}{20}{figure.caption.19}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces Distribution of the count of followers and followees related to fake and real news\relax }}{21}{figure.caption.20}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Follower count of users in PolitiFact dataset}}}{21}{figure.caption.20}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Followee count of users in PolitiFact dataset}}}{21}{figure.caption.20}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Follower count of users in Gossipcop dataset}}}{21}{figure.caption.20}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Followee count of users in PolitiFact dataset}}}{21}{figure.caption.20}%
\contentsline {figure}{\numberline {1.5}{\ignorespaces Distributions of propagation path lengths for fake and real news (original and log-transformed).\relax }}{23}{figure.caption.23}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Raw distribution}}}{23}{figure.caption.23}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Log-transformed distribution}}}{23}{figure.caption.23}%
\contentsline {figure}{\numberline {1.6}{\ignorespaces Total paths likes vs. propagation path lengths\relax }}{26}{figure.caption.27}%
\contentsline {figure}{\numberline {1.7}{\ignorespaces Schematization of tweets extraction from articles. $\ell $ is a fixed length\relax }}{27}{figure.caption.28}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Embeddings concatenation with MLP head architecture\relax }}{32}{figure.caption.32}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Text embeddings reduction with source embedding architecture\relax }}{35}{figure.caption.38}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Text embeddings reduction with average engagement per source embedding\relax }}{37}{figure.caption.40}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Gate fusioning of text and average engagement per source embeddings\relax }}{39}{figure.caption.42}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Bidirectional GRU\relax }}{42}{figure.caption.45}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces CNN-based model\relax }}{43}{figure.caption.47}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Transformer encoder-based model\relax }}{45}{figure.caption.49}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces PCA visualizations of titles and caption embeddings\relax }}{51}{figure.caption.53}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Titles' embeddings}}}{51}{figure.caption.53}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Captions' embeddings}}}{51}{figure.caption.53}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Evolution of modelsâ€™ precision and recall as a function of the weighting scheme in the $F\text {-}\beta $ score. By adjusting the balance between precision and recall during model selection, we can observe how the models shift their behavior: higher weights on recall lead to identifying more true viral posts (higher recall) but at the cost of precision, while lower weights have the opposite effect.\relax }}{55}{figure.caption.56}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Precision values obtained when varying the weight ratio in the $F\text {-}\beta $ score}}}{55}{figure.caption.56}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Recall values obtained when varying the weight ratio in the $F\text {-}\beta $ score}}}{55}{figure.caption.56}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Dimensionality reduction of numerical data using PCA and t-SNE -- fake news detection\relax }}{59}{figure.caption.59}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {PCA reduction}}}{59}{figure.caption.59}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {t-SNE reduction}}}{59}{figure.caption.59}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Dimensionality reduction of numerical data using PCA and t-SNE -- virality prediction\relax }}{61}{figure.caption.62}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {PCA reduction}}}{61}{figure.caption.62}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {t-SNE reduction}}}{61}{figure.caption.62}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces F1 Scores of GRU Model for Fake News Detection and Virality Prediction for different $\ell $ values. \textbf {Note}: y-axis starting at 0.7 for better readability\relax }}{63}{figure.caption.64}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1}{\ignorespaces Screenshot of monitoring data during training on \emph {wandb}\relax }}{75}{figure.caption.72}%
