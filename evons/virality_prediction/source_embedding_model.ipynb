{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DLw6kMN4iCOG"
      },
      "outputs": [],
      "source": [
        "# IMPORT\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import wandb  # Weights & Biases for experiment tracking and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWeVGWzJdnm4",
        "outputId": "ec8947c2-6497-4fd4-a18d-df8e97cd1840"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Log in to Weights & Biases for experiment tracking\n",
        "wandb.login(key='YOUR_KEY_HERE')\n",
        "\n",
        "# Preprocessing Data\n",
        "df = pd.read_csv('../data/evons.csv')\n",
        "\n",
        "# Fill missing values in the 'title' and 'description' columns with empty strings\n",
        "df['title'] = df['title'].fillna('')\n",
        "df['description'] = df['description'].fillna('')\n",
        "df['media_source'] = df['media_source'].astype('category').cat.codes\n",
        "\n",
        "# Calculate engagement 95 percentile threshold for virality\n",
        "engagement_threshold = df['fb_engagements'].quantile(0.95)\n",
        "df['is_viral'] = (df['fb_engagements'] > engagement_threshold).astype(int)\n",
        "\n",
        "\n",
        "# Select relevant columns for the task\n",
        "df = df[['title', 'description', 'media_source','fb_engagements', 'is_viral']]\n",
        "\n",
        "X_text = df[['title','description','media_source']].values  # Features: title and description\n",
        "y = df['is_viral'].values  # Labels: is_viral (binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T0-nxmylN6qc"
      },
      "outputs": [],
      "source": [
        "# Define a PyTorch module for text embedding using a pre-trained BERT model\n",
        "class TextEmbedder(nn.Module):\n",
        "    def __init__(self, bert_model, tokenizer):\n",
        "        super().__init__()\n",
        "        self.bert_model = bert_model.to(device)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Tokenize the input text and move tensors to the specified device\n",
        "        inputs = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        # Pass the tokenized input through the BERT model\n",
        "        output = self.bert_model(**inputs)\n",
        "        # Return the embeddings for the [CLS] token (first token in each sequence)\n",
        "        return output.last_hidden_state[:, 0, :]\n",
        "\n",
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asLxIQdVNya7"
      },
      "outputs": [],
      "source": [
        "_lazy_text_embedder = None  # cache\n",
        "\n",
        "def compute_embeddings(texts, batch_size=64, title_desc=None):\n",
        "    global _lazy_text_embedder\n",
        "    # Attempt to load precomputed embeddings first (no model download if present)\n",
        "    try:\n",
        "        if title_desc == 'title':\n",
        "            return torch.load('../data/title_embeddings.pt')\n",
        "        elif title_desc == 'desc':\n",
        "            return torch.load('../data/desc_embeddings.pt')\n",
        "    except Exception:\n",
        "        pass  # Will fall back to computing\n",
        "\n",
        "    # Lazy initialization of model ONLY now\n",
        "    if _lazy_text_embedder is None:\n",
        "        tokenizer = AutoTokenizer.from_pretrained('FacebookAI/roberta-base')\n",
        "        bert_model = AutoModel.from_pretrained('FacebookAI/roberta-base')\n",
        "        _lazy_text_embedder = TextEmbedder(bert_model, tokenizer).to(device)\n",
        "\n",
        "    text_embedder = _lazy_text_embedder\n",
        "    all_embeddings = []\n",
        "\n",
        "    text_embedder.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size)):\n",
        "            batch_texts = [str(t) for t in texts[i:i+batch_size]]\n",
        "            emb = text_embedder(batch_texts).detach().cpu()\n",
        "            all_embeddings.append(emb)\n",
        "\n",
        "    return torch.cat(all_embeddings, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OILiojNcN23E",
        "outputId": "cc21dbf7-3133-49ba-e5de-ed223af94a26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape embeddings titles: torch.Size([92969, 768])\n",
            "Shape embeddings descriptions: torch.Size([92969, 768])\n"
          ]
        }
      ],
      "source": [
        "# Compute embeddings for titles and descriptions in the dataset\n",
        "# If precomputed embeddings are available, they will be loaded\n",
        "# Otherwise, embeddings will be computed on-the-fly\n",
        "title_embeddings = compute_embeddings(X_text[:, 0], title_desc='title')\n",
        "desc_embeddings = compute_embeddings(X_text[:, 1], title_desc='desc')\n",
        "sources = X_text[:, 2]\n",
        "\n",
        "print(f\"Shape embeddings titles: {title_embeddings.shape}\")\n",
        "print(f\"Shape embeddings descriptions: {desc_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iQcoTdlweKEf"
      },
      "outputs": [],
      "source": [
        "# Define a custom PyTorch Dataset for precomputed embeddings\n",
        "class PrecomputedDataset(Dataset):\n",
        "    def __init__(self, title_embeddings, desc_embeddings, sources, labels):\n",
        "        # Initialize the dataset with title embeddings, description embeddings, and labels\n",
        "        self.title_embeddings = title_embeddings\n",
        "        self.desc_embeddings = desc_embeddings\n",
        "        self.sources = torch.tensor(sources.astype(int), dtype=torch.long)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Convert labels to PyTorch tensors\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples in the dataset\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve a single sample (title embedding, description embedding, sources, label) by index\n",
        "        return (self.title_embeddings[idx], self.desc_embeddings[idx], self.sources[idx]), self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N9rqGUtIeW3c"
      },
      "outputs": [],
      "source": [
        "class ClassifierModel(nn.Module):\n",
        "    def __init__(self, dropout_p=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear layer to reduce dimensionality of title embeddings (from 768 → 192)\n",
        "        self.reduce_title = nn.Linear(768, 192)\n",
        "\n",
        "        # Linear layer to reduce dimensionality of description embeddings (from 768 → 192)\n",
        "        self.reduce_desc = nn.Linear(768, 192)\n",
        "\n",
        "        # Embedding layer to represent categorical \"source\" IDs (11 possible sources, mapped to 192-dim vectors)\n",
        "        self.source_embedding = nn.Embedding(11, 192)\n",
        "\n",
        "        # Final linear layer for binary classification (input: concatenated 3 vectors of size 192, output: 1 logit)\n",
        "        self.linear_1 = nn.Linear(192 * 3, 1)  # 1 output for binary classification\n",
        "\n",
        "        # Activation function\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "        # Dropout layer to prevent overfitting\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Unpack inputs (title embeddings, description embeddings, and categorical source IDs)\n",
        "        title_embedding, desc_embedding, source = data\n",
        "\n",
        "        # Reduce and activate title embedding\n",
        "        embed_title = self.reduce_title(title_embedding.to(device))\n",
        "        embed_title = self.gelu(embed_title)\n",
        "\n",
        "        # Reduce and activate description embedding\n",
        "        embed_desc = self.reduce_desc(desc_embedding.to(device))\n",
        "        embed_desc = self.gelu(embed_desc)\n",
        "\n",
        "        # Embed categorical source ID and apply activation\n",
        "        source = self.source_embedding(source.to(device))\n",
        "        source = self.gelu(source)\n",
        "\n",
        "        # Concatenate reduced title, description, and source embeddings into a single feature vector\n",
        "        x = torch.cat([embed_title, embed_desc, source], dim=1)\n",
        "\n",
        "        # Apply final classification layer → raw logits (before sigmoid)\n",
        "        logits = self.linear_1(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kmXFkNaqelXp"
      },
      "outputs": [],
      "source": [
        "# Function to plot a confusion matrix as a heatmap\n",
        "def plot_confusion_matrix_image(y_true, y_pred, labels):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"BuGn\", xticklabels=labels, yticklabels=labels, cbar=True)\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"Actual\")\n",
        "    ax.set_title(\"Confusion Matrix\")\n",
        "    return fig\n",
        "\n",
        "# Function to evaluate the model on the test set and log metrics to Weights & Biases\n",
        "def test_model_wandb(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\n",
        "    total_loss = 0\n",
        "    all_probs, all_targets = [], []\n",
        "\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        y_batch = y_batch.to(device).float().unsqueeze(1)  # Move labels to the device and reshape\n",
        "        y_logits = model(x_batch)  # Get model predictions (logits)\n",
        "        loss = criterion(y_logits, y_batch)  # Compute the loss\n",
        "        total_loss += loss.item()  # Accumulate the total loss\n",
        "        probs = torch.sigmoid(y_logits).detach().cpu().squeeze(1)  # Apply sigmoid to get probabilities\n",
        "        all_probs.append(probs)  # Collect probabilities\n",
        "        all_targets.append(y_batch.detach().cpu().squeeze(1).long())  # Collect true labels\n",
        "\n",
        "    all_probs = torch.cat(all_probs)  # Concatenate all probabilities\n",
        "    all_targets = torch.cat(all_targets)  # Concatenate all true labels\n",
        "    all_preds = (all_probs > 0.5).long()  # Convert probabilities to binary predictions\n",
        "\n",
        "    fig = plot_confusion_matrix_image(all_targets.numpy(), all_preds.numpy(), [0, 1])  # create confusion matrix\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    metrics = {\n",
        "        \"test_loss\": total_loss / len(test_loader),\n",
        "        \"test_accuracy\": accuracy_score(all_targets, all_preds),\n",
        "        \"test_balanced_accuracy\": balanced_accuracy_score(all_targets, all_preds),\n",
        "        \"test_f1\": f1_score(all_targets, all_preds),\n",
        "        \"test_precision\": precision_score(all_targets, all_preds),\n",
        "        \"test_recall\": recall_score(all_targets, all_preds),\n",
        "        \"test_roc_auc\": roc_auc_score(all_targets, all_probs),\n",
        "        \"test_confusion_matrix\": wandb.Image(fig),\n",
        "    }\n",
        "\n",
        "    wandb.log(metrics)  # Log metrics to Weights & Biases\n",
        "    plt.close(fig)  # Close the confusion matrix plot\n",
        "    return metrics\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def train_single_fold(config, fold, train_indices, val_indices, title_embeddings, desc_embeddings,sources, y, project_name):\n",
        "    # Name this training run according to the fold\n",
        "    run_name = f\"fold_{fold}\"\n",
        "\n",
        "    # Start a new Weights & Biases run for experiment tracking\n",
        "    with wandb.init(config=config, project=project_name, name=run_name, save_code=True):\n",
        "\n",
        "        # Create training dataset from precomputed embeddings\n",
        "        train_dataset = PrecomputedDataset(\n",
        "            title_embeddings[train_indices],\n",
        "            desc_embeddings[train_indices],\n",
        "            sources[train_indices],\n",
        "            y[train_indices]\n",
        "        )\n",
        "\n",
        "        # Create validation dataset from precomputed embeddings\n",
        "        val_dataset = PrecomputedDataset(\n",
        "            title_embeddings[val_indices],\n",
        "            desc_embeddings[val_indices],\n",
        "            sources[val_indices],\n",
        "            y[val_indices]\n",
        "        )\n",
        "\n",
        "        # Wrap datasets in PyTorch DataLoader for batching\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "        # Log the fold number in Weights & Biases\n",
        "        wandb.log({\"fold\": fold})\n",
        "\n",
        "        # Compute class imbalance ratio to adjust loss function\n",
        "        num_pos = (y[train_indices] == 1).sum()\n",
        "        num_neg = (y[train_indices] == 0).sum()\n",
        "        pos_weight = torch.tensor([num_neg / max(num_pos, 1)], dtype=torch.float).to(device)\n",
        "\n",
        "        # Initialize model, optimizer, and loss function\n",
        "        model = ClassifierModel(dropout_p=config['dropout']).to(device)\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Weighted loss for imbalanced classes\n",
        "\n",
        "        # Create a learning rate scheduler with linear warmup/decay\n",
        "        total_steps = len(train_loader) * config['num_epochs']\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "        print(f\"Training fold {fold}...\")\n",
        "\n",
        "        # Track the best validation F1 score\n",
        "        best_f1 = 0.0\n",
        "        best_epoch = 0\n",
        "\n",
        "        # Training loop across epochs\n",
        "        for epoch in range(config['num_epochs']):\n",
        "            model.train()  # Put model in training mode\n",
        "            total_loss = 0\n",
        "            all_probs, all_targets = [], []\n",
        "\n",
        "            # Iterate through training batches\n",
        "            for x_batch, y_batch in tqdm(train_loader, desc=f\"Fold {fold}, Epoch {epoch+1}\"):\n",
        "                optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "                # Prepare labels and run forward pass\n",
        "                y_batch_float = y_batch.to(device).float().unsqueeze(1)\n",
        "                y_logits = model(x_batch)\n",
        "\n",
        "                # Compute weighted loss\n",
        "                loss = criterion(y_logits, y_batch_float)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Backpropagation and optimizer update\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Collect predictions and true labels for metrics\n",
        "                probs = torch.sigmoid(y_logits).detach().cpu().squeeze(1)\n",
        "                all_probs.append(probs)\n",
        "                all_targets.append(y_batch.detach().cpu().long())\n",
        "\n",
        "            # Concatenate predictions and labels across all batches\n",
        "            all_probs = torch.cat(all_probs)\n",
        "            all_targets = torch.cat(all_targets)\n",
        "            all_preds = (all_probs > 0.5).long()  # Convert probs to binary predictions\n",
        "\n",
        "            # Plot and log confusion matrix for training set\n",
        "            fig = plot_confusion_matrix_image(all_targets.numpy(), all_preds.numpy(), [0, 1])\n",
        "\n",
        "            # Compute and log training metrics\n",
        "            train_metrics = {\n",
        "                \"epoch\": epoch,\n",
        "                \"train_loss\": total_loss / len(train_loader),\n",
        "                \"train_accuracy\": accuracy_score(all_targets, all_preds),\n",
        "                \"train_balanced_accuracy\": balanced_accuracy_score(all_targets, all_preds),\n",
        "                \"train_f1\": f1_score(all_targets, all_preds),\n",
        "                \"train_precision\": precision_score(all_targets, all_preds),\n",
        "                \"train_recall\": recall_score(all_targets, all_preds),\n",
        "                \"train_roc_auc\": roc_auc_score(all_targets, all_probs),\n",
        "                \"train_confusion_matrix\": wandb.Image(fig),\n",
        "                \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "            }\n",
        "\n",
        "            wandb.log(train_metrics)\n",
        "            plt.close(fig)\n",
        "\n",
        "            # Evaluate on validation set and log metrics\n",
        "            val_metrics = test_model_wandb(model, val_loader)\n",
        "\n",
        "            # Update \"best\" model if F1 improved\n",
        "            current_f1 = val_metrics[\"test_f1\"]\n",
        "            if current_f1 > best_f1:\n",
        "                best_f1 = current_f1\n",
        "                best_epoch = epoch\n",
        "                best_metrics = val_metrics.copy()\n",
        "                best_metrics[\"best_epoch\"] = best_epoch\n",
        "\n",
        "                # Prefix keys with \"best_\" for logging\n",
        "                best_log_metrics = {f\"best_{key}\": value for key, value in best_metrics.items() if key != \"test_confusion_matrix\"}\n",
        "                wandb.log(best_log_metrics)\n",
        "\n",
        "                print(f\"New best validation f1: {best_f1:.4f} at epoch {epoch + 1}\")\n",
        "\n",
        "        # Attach fold info to final best metrics\n",
        "        best_metrics[\"fold\"] = fold\n",
        "        print(f\"Fold {fold} completed. Best f1: {best_f1:.4f} at epoch {best_epoch + 1}\")\n",
        "\n",
        "        return best_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlkKzC1LfMnm"
      },
      "outputs": [],
      "source": [
        "def run_cross_validation_sweep(config=None):\n",
        "    \"\"\"\n",
        "    Perform cross-validation to evaluate the model's performance across multiple folds.\n",
        "\n",
        "    Args:\n",
        "        config (dict, optional): Configuration dictionary containing hyperparameters such as\n",
        "            - learning_rate: Learning rate for the optimizer.\n",
        "            - weight_decay: Weight decay (L2 regularization) for the optimizer.\n",
        "            - dropout: Dropout probability for the model.\n",
        "            - num_epochs: Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries containing the best metrics for each fold.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        # Default configuration if none is provided\n",
        "        config = {\n",
        "            'learning_rate': 1e-4,\n",
        "            'weight_decay': 0.01,\n",
        "            'dropout': 0.1,\n",
        "            'num_epochs': 50\n",
        "        }\n",
        "\n",
        "    # Define the project name for Weights & Biases logging\n",
        "    project_name = 'PROJECT_NAME'\n",
        "\n",
        "    # Initialize Stratified K-Fold cross-validation with 10 splits\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    # List to store the best metrics for each fold\n",
        "    all_best_metrics = []\n",
        "\n",
        "    # Iterate through each fold\n",
        "    for fold, (train_indices, val_indices) in enumerate(skf.split(title_embeddings, y)):\n",
        "        print(f\"\\n=== FOLD {fold + 1}/10 ===\")\n",
        "\n",
        "        # Train the model on the current fold and retrieve the best metrics\n",
        "        best_fold_metrics = train_single_fold(\n",
        "            config, fold + 1, train_indices, val_indices,\n",
        "            title_embeddings, desc_embeddings, sources, y, project_name\n",
        "        )\n",
        "        all_best_metrics.append(best_fold_metrics)\n",
        "\n",
        "    # Print a summary of the best metrics across all folds\n",
        "    print(f\"\\n=== CROSS-VALIDATION SUMMARY (BEST METRICS) ===\")\n",
        "    metric_names = ['test_accuracy', 'test_balanced_accuracy', 'test_f1', 'test_precision', 'test_recall', 'test_roc_auc']\n",
        "\n",
        "    for metric_name in metric_names:\n",
        "        # Compute the mean and standard deviation for each metric\n",
        "        values = [fold_metrics[metric_name] for fold_metrics in all_best_metrics]\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values)\n",
        "        print(f\"Best {metric_name}: {mean_val:.4f} ± {std_val:.4f}\")\n",
        "\n",
        "    # Print the best epoch for each fold\n",
        "    print(f\"\\nBest epochs for each fold:\")\n",
        "    for i, fold_metrics in enumerate(all_best_metrics):\n",
        "        print(f\"Fold {i+1}: Epoch {fold_metrics['best_epoch'] + 1} (Balanced Accuracy: {fold_metrics['test_balanced_accuracy']:.4f})\")\n",
        "\n",
        "    return all_best_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27yD2YRUqP5m"
      },
      "outputs": [],
      "source": [
        "# Configuration for the experiment\n",
        "config = {\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 0.01,\n",
        "    'dropout': 0.1,\n",
        "    'num_epochs': 50\n",
        "}\n",
        "\n",
        "# Run cross-validation with separate wandb runs for each fold\n",
        "all_fold_results = run_cross_validation_sweep(config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
